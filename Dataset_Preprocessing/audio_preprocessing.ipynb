{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class AudioPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "        self.model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(self.device)\n",
    "        self.model.eval()\n",
    "        self.positional_encoder = PositionalEncoding(d_model=768).to(self.device)\n",
    "\n",
    "    def get_embedding(self, audio_path):\n",
    "        \"\"\"오디오 파일 처리 및 임베딩 추출\"\"\"\n",
    "        try:\n",
    "            # 오디오 로드 및 전처리\n",
    "            waveform, sample_rate = torchaudio.load(audio_path)\n",
    "            \n",
    "            # 스테레오를 모노로 변환\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "            # 샘플링 레이트 변환\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            \n",
    "            # Wav2Vec2 입력 처리\n",
    "            inputs = self.processor(\n",
    "                waveform.squeeze().numpy(),\n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True\n",
    "            )\n",
    "            \n",
    "            input_values = inputs.input_values.to(self.device)\n",
    "            \n",
    "            # 특징 추출\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_values)\n",
    "                features = outputs.last_hidden_state\n",
    "                features = self.positional_encoder(features)\n",
    "                features = features.mean(dim=1).squeeze().cpu().numpy()\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"오디오 처리 중 오류 발생: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def extract_audio_features(audio_path):\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    return preprocessor.get_embedding(audio_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
