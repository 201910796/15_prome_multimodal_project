{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps  # Pillow 모듈\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms  # torchvision 관련 모듈\n",
    "\n",
    "import pandas as pd\n",
    "import h5py  # HDF5 파일 형식을 위한 라이브러리\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크기 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 경로 지정\n",
    "image_path = r'C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset\\image\\EmotionROI\\images\\anger\\1.jpg'\n",
    "\n",
    "# 이미지 열기\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 이미지 크기 확인\n",
    "width, height = image.size\n",
    "print(f\"Image size: {width} x {height} pixels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 정사각형 크기 지정 \n",
    "desired_size = 512\n",
    "\n",
    "# 패딩을 추가하여 지정한 크기의 정사각형으로 변환\n",
    "padded_image = ImageOps.pad(image, (desired_size, desired_size), color=(0, 0, 0))  # (0, 0, 0)은 검은색 패딩\n",
    "padded_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지가 있는 폴더 경로\n",
    "input_folder = r'C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset\\image\\EmotionROI\\ground_truth\\surprise'  # 원본 이미지 폴더 경로\n",
    "output_folder = r'C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset_preprocessed\\EmotionROI_padding\\ground_truth\\surprise'  # 결과를 저장할 폴더 경로\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 원하는 정사각형 크기 지정 (예: 512x512)\n",
    "desired_size = 512\n",
    "\n",
    "# 폴더 내 모든 JPG 이미지에 대해 반복 실행\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith('.jpg'):  # JPG 확장자만 처리\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # 이미지 열기\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 패딩을 추가하여 지정한 크기의 정사각형으로 변환\n",
    "        padded_image = ImageOps.pad(image, (desired_size, desired_size), color=0)  \n",
    "        \n",
    "        # 결과 이미지를 저장\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        padded_image.save(output_path)\n",
    "\n",
    "print(\"전처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 중앙 크롭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙 크롭\n",
    "cropped_image = ImageOps.fit(image, (512, 512), method=0, bleed=0.0, centering=(0.5, 0.5))\n",
    "cropped_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 만들기 - images ##\n",
    "\n",
    "# 이미지가 있는 폴더 경로\n",
    "input_folder = r'C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset\\EmotionROI\\ground_truth\\surprise'  # 원본 이미지 폴더 경로\n",
    "output_folder = r'C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset_preprocessed\\EmotionROI_crop\\ground_truth\\surprise'  # 결과를 저장할 폴더 경로\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 원하는 정사각형 크기 지정 (예: 512x512)\n",
    "desired_size = 512\n",
    "\n",
    "# 폴더 내 모든 JPG 이미지에 대해 반복 실행\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith('.jpg'):  # JPG 확장자만 처리\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # 이미지 열기\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 중앙 크롭을 수행하여 지정한 크기의 정사각형으로 변환\n",
    "        cropped_image = ImageOps.fit(image, (desired_size, desired_size), method=0, bleed=0.0, centering=(0.5, 0.5))\n",
    "        \n",
    "        # 결과 이미지를 저장\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cropped_image.save(output_path)\n",
    "\n",
    "print(\"전처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'sadness': 4, 'surprise': 5}\n"
     ]
    }
   ],
   "source": [
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # VATT 모델에 맞게 이미지 크기 조정\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 정규화 값\n",
    "])\n",
    "\n",
    "# ImageFolder를 사용하여 데이터셋 로드\n",
    "image_folder_path = r\"C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset_preprocessed\\EmotionROI_crop\\images\"  # 데이터셋 폴더 경로\n",
    "image_dataset = datasets.ImageFolder(root=image_folder_path, transform=transform)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "image_dataloader = DataLoader(image_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 클래스 인덱스 확인\n",
    "print(image_dataset.class_to_idx)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\cuda_torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cuda_torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 image_embeddings_with_labels_768_augmented_images.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 감정 레이블 매핑\n",
    "emotion_label_mapping = {'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'sadness': 4, 'surprise': 5}\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 시 GPU로, 아니면 CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 이미지 전처리 설정 (이미지를 224x224 크기로 변환하고, 텐서로 변환)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 이미지 폴더에서 이미지와 레이블을 배치 단위로 로드하는 함수\n",
    "def load_images_in_batches(image_folder_path, batch_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for emotion, label in emotion_label_mapping.items():\n",
    "        folder_path = os.path.join(image_folder_path, emotion)\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            if img_name.endswith('.jpg'):  # 이미지 파일만 처리\n",
    "                img_path = os.path.join(folder_path, img_name)\n",
    "                image = Image.open(img_path)\n",
    "                image = preprocess(image)\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "                # 배치 크기만큼 모이면 처리\n",
    "                if len(images) == batch_size:\n",
    "                    images_tensor = torch.stack(images).to(device)\n",
    "                    labels_tensor = torch.tensor(labels).to(device)\n",
    "                    yield images_tensor, labels_tensor\n",
    "                    images = []\n",
    "                    labels = []\n",
    "    \n",
    "    # 남은 이미지 처리\n",
    "    if len(images) > 0:\n",
    "        images_tensor = torch.stack(images).to(device)\n",
    "        labels_tensor = torch.tensor(labels).to(device)\n",
    "        yield images_tensor, labels_tensor\n",
    "\n",
    "# ResNet 모델을 사용하여 중간 레이어의 특징을 추출\n",
    "def extract_and_transform_features(images_tensor):\n",
    "    model = models.resnet50(pretrained=True).to(device)  # 모델을 GPU로 이동\n",
    "    model.eval()  # 추론 모드로 설정\n",
    "    \n",
    "    fc = nn.Linear(2048, 768).to(device)  # FC 레이어도 GPU로 이동\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # ResNet의 전체 네트워크를 통과시킴\n",
    "        features = model.conv1(images_tensor)\n",
    "        features = model.bn1(features)\n",
    "        features = model.relu(features)\n",
    "        features = model.maxpool(features)\n",
    "        features = model.layer1(features)\n",
    "        features = model.layer2(features)\n",
    "        features = model.layer3(features)\n",
    "        features = model.layer4(features)  # layer4를 사용하여 2048차원 벡터 추출\n",
    "        features = model.avgpool(features)  # 평균 풀링 적용\n",
    "        features = torch.flatten(features, 1)  # 2048차원 벡터로 변환\n",
    "        \n",
    "        # 2048차원 특징 벡터를 768차원으로 축소\n",
    "        features_768 = fc(features)\n",
    "    \n",
    "    return features_768\n",
    "\n",
    "BATCH_SIZE = 16  # 배치 크기 설정\n",
    "\n",
    "# DataFrame 저장 준비\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# 배치 단위로 이미지를 처리하고 특징 벡터를 추출\n",
    "for images_tensor, labels_tensor in load_images_in_batches(image_folder_path, BATCH_SIZE):\n",
    "    features_768 = extract_and_transform_features(images_tensor)\n",
    "    all_features.append(features_768.cpu().numpy())  # CPU로 이동하여 numpy 배열로 변환\n",
    "    all_labels.append(labels_tensor.cpu().numpy())  # 레이블도 CPU로 이동 후 numpy로 변환\n",
    "    \n",
    "    # GPU 메모리 해제\n",
    "    del images_tensor, labels_tensor, features_768\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# DataFrame으로 변환 (768차원의 임베딩 벡터 + 감정 레이블)\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "df = pd.DataFrame(features_array, columns=[f'embedding_{i}' for i in range(768)])\n",
    "df['emotion_label'] = labels_array.astype(int)  # 레이블은 정수형으로 저장\n",
    "\n",
    "# CSV 파일로 저장 (텍스트 형식과 동일한 형식)\n",
    "csv_output_path = 'image_embeddings_with_labels_768_augmented_images.csv'\n",
    "df.to_csv(csv_output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"CSV 파일이 {csv_output_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 불러오기\n",
    "df = csv_output_path\n",
    "# 각 감정 레이블의 개수 계산\n",
    "label_counts = df['emotion_label'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
