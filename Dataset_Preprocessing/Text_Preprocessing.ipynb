{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel # BERT 모델 및 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일에서 데이터 읽기\n",
    "csv_file = r'C:\\project_files\\Multimodal_Auto _BGM_Addition_System\\dataset_preprocessed\\text\\combined_emotion_dataset _neutral_x.csv'  \n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감정 비율 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 레이블의 순서\n",
    "emotion_order = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sad\", \"surprise\"]\n",
    "\n",
    "# 각 감정 레이블의 개수 출력\n",
    "emotion_counts = df['감정'].value_counts()\n",
    "\n",
    "# 지정된 emotion_order 순서에 따라 감정 개수 정렬\n",
    "emotion_counts = emotion_counts.reindex(emotion_order, fill_value=0)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"각 감정 레이블의 개수:\")\n",
    "print(emotion_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kobert 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 라벨 매핑\n",
    "emotion_label_mapping = {'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'sadness': 4, 'surprise': 5}\n",
    "\n",
    "# 결측치가 있는 행을 삭제\n",
    "df = df.dropna(subset=['문장', '감정'])\n",
    "\n",
    "# 감정이 emotion_label_mapping에 존재하는 경우만 필터링\n",
    "df = df[df['감정'].isin(emotion_label_mapping.keys())]\n",
    "\n",
    "texts = df['문장'].tolist()\n",
    "emotions = df['감정'].tolist()\n",
    "\n",
    "# 텍스트와 감정 레이블이 잘 일치하는지 확인\n",
    "if len(texts) != len(emotions):\n",
    "    print(f\"텍스트와 라벨의 길이가 다릅니다. 텍스트 개수: {len(texts)}, 라벨 개수: {len(emotions)}\")\n",
    "\n",
    "# 감정 라벨을 숫자로 변환\n",
    "labels = [emotion_label_mapping[emotion] for emotion in emotions]\n",
    "\n",
    "print(f\"최종 텍스트 개수: {len(texts)}, 최종 라벨 개수: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. KoBERT 모델과 토크나이저 불러오기\n",
    "model_name = 'monologg/kobert'  # Hugging Face에서 제공하는 KoBERT 모델 이름\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)  # KoBERT 전용 토크나이저\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. 텍스트 전처리 (특수문자 제거 함수 추가)\n",
    "def clean_text(text):\n",
    "    # 특수문자 및 비정상적인 문자를 제거 (한글, 영어, 숫자, 공백 외의 문자를 제거)\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 4. 텍스트 데이터 클리닝\n",
    "texts = df['문장'].tolist()\n",
    "texts = [clean_text(str(text)) for text in texts if isinstance(text, str)]\n",
    "\n",
    "# 감정 데이터를 숫자로 변환 (emotion_label_mapping)\n",
    "emotion_label_mapping = {'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'sad': 4, 'surprise': 5}\n",
    "labels = [emotion_label_mapping[emotion] for emotion in df['감정'].tolist()]\n",
    "\n",
    "# 5. 텍스트 전처리 함수 정의\n",
    "def preprocess_texts(texts, tokenizer, max_len=128):\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_tensors='pt',\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "# 6. Dataset 클래스 정의\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label\n",
    "\n",
    "# 7. 임베딩 추출 함수 정의\n",
    "def get_embeddings(texts, model, tokenizer, batch_size=32):\n",
    "    dataset = TextDataset(texts, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_embeddings = []\n",
    "\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        for batch_texts, _ in dataloader:\n",
    "            inputs = preprocess_texts(batch_texts, tokenizer).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state  # [CLS] 임베딩 추출\n",
    "            cls_embeddings = embeddings[:, 0, :]  # [CLS] 토큰에 해당하는 임베딩\n",
    "            all_embeddings.append(cls_embeddings.cpu().numpy())  # CPU로 이동 후 리스트에 저장\n",
    "\n",
    "    all_embeddings = [embedding for batch in all_embeddings for embedding in batch]  # 2D 리스트를 1D로 변환\n",
    "    return all_embeddings\n",
    "\n",
    "# 8. 임베딩 추출\n",
    "embeddings = get_embeddings(texts, model, tokenizer, batch_size=32)\n",
    "\n",
    "# 9. 임베딩과 레이블의 개수를 맞추기 위해 길이 차이가 있을 경우, 마지막 값 삭제\n",
    "if len(embeddings) != len(labels):\n",
    "    print(f\"임베딩 수: {len(embeddings)}, 라벨 수: {len(labels)}\")\n",
    "    if len(embeddings) > len(labels):\n",
    "        embeddings = embeddings[:len(labels)]\n",
    "    elif len(labels) > len(embeddings):\n",
    "        labels = labels[:len(embeddings)]  # 문제가 되는 값 삭제\n",
    "\n",
    "# 10. CSV로 저장할 데이터 준비 (문장과 임베딩을 결합)\n",
    "embedding_df = pd.DataFrame(embeddings, columns=[f\"embedding_{i}\" for i in range(embeddings[0].shape[0])])  # 임베딩 열 생성\n",
    "embedding_df['emotion_label'] = labels  # 감정 라벨 추가\n",
    "\n",
    "# 11. CSV 파일로 저장\n",
    "output_csv = 'text_embeddings_with_labels_new.csv'\n",
    "embedding_df.to_csv(output_csv, index=False)\n",
    "print(f\"임베딩 데이터가 {output_csv}로 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
